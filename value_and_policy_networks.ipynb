{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nN-7tPDiDTKn",
    "outputId": "a32ffe50-9c22-45d0-d574-309bd5f5dbb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/My Drive/ENSC/3A/S9/AlphaGo\n",
      " alpha_all.pdf\t\t Goban.py\t        NNV5.ipynb\n",
      " alphago.pdf\t\t Labels_next_move.npy   __pycache__\n",
      " alphago_zero.pdf\t Labels.npy\t        samples-9x9.json.gz\n",
      " Features_multiple.npy\t Labels_value.npy       training_1\n",
      " Features.npy\t\t NNV3.ipynb\n",
      "'fiche alphago.gdoc'\t NNV4.ipynb\n"
     ]
    }
   ],
   "source": [
    "#but du code: récupérer la dataset et la preprocessing\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "%cd /content/drive/My Drive/ENSC/3A/S9/AlphaGo/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "By_F22ubz2iY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Dense, Flatten, Add\n",
    "from tensorflow.keras.activations import linear, relu, tanh\n",
    "import numpy as np\n",
    "import random\n",
    "import Goban\n",
    "import keras\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fEVvlqiBzpo1"
   },
   "outputs": [],
   "source": [
    "#aide: https://stackoverflow.com/questions/62285475/why-am-i-having-this-error-typeerror-failed-to-convert-object-of-type-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "N1Svc9x9zpo6"
   },
   "outputs": [],
   "source": [
    "def get_raw_data_go():\n",
    "    ''' Returns the set of samples from the local file or download it if it does not exists'''\n",
    "\n",
    "    raw_samples_file = \"samples-9x9.json.gz\"\n",
    "\n",
    "    if not os.path.isfile(raw_samples_file):\n",
    "        print(\"File\", raw_samples_file, \"not found, I am downloading it...\", end=\"\")\n",
    "        urllib.request.urlretrieve(\"https://www.labri.fr/perso/lsimon/ia-inge2/samples-9x9.json.gz\", \"samples-9x9.json.gz\")\n",
    "        print(\" Done\")\n",
    "\n",
    "    with gzip.open(\"samples-9x9.json.gz\") as fz:\n",
    "        data = json.loads(fz.read().decode(\"utf-8\"))\n",
    "    return data\n",
    "\n",
    "def fulfill_board(list_moves):\n",
    "    board=Goban.Board()\n",
    "    list_col_letters=['A','B','C','D','E','F','G','H','I']\n",
    "    for i in range(len(list_moves)):\n",
    "        board.push(b.name_to_flat(list_moves[i]))\n",
    "    return board\n",
    "\n",
    "\n",
    "def get_all_boards_from_game(list_moves):\n",
    "    global_board=np.zeros([9,9,len(list_moves)])\n",
    "    list_col_letters=['A','B','C','D','E','F','G','H','I']\n",
    "    current_board=Goban.Board()\n",
    "    for i in range(len(list_moves)):\n",
    "        #print(list_moves[i])\n",
    "        #print(i)\n",
    "        #print(current_board.name_to_flat(list_moves[i])) #erreur à 14\n",
    "        try:\n",
    "            current_board.push(current_board.name_to_flat(list_moves[i]))\n",
    "        except KeyError:\n",
    "            print('ERROR')\n",
    "            break\n",
    "            #print(list_moves[i]) #A9\n",
    "            #print(name_to_flat(list_moves[i]))\n",
    "            #print(current_board.name_to_flat(list_moves[i])) #72\n",
    "            #print(list_moves)\n",
    "        \n",
    "        global_board[:,:,i]=current_board._board.reshape(9,9)\n",
    "    return global_board\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOW3LH7CzppC",
    "outputId": "d749b1c5-1b25-4759-c497-cfc6af246e5c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_single_data(dataset):\n",
    "\n",
    "    rand_sample=random.randint(0,len(dataset)-1)\n",
    "    first_game=dataset[rand_sample]\n",
    "    list_moves=first_game.get('list_of_moves')\n",
    "\n",
    "\n",
    "    nb_boards_of_interest=4\n",
    "\n",
    "    #on prend 4 boards\n",
    "    boards=get_all_boards_from_game(list_moves)\n",
    "    #on prend un board au hasard qui contienne assez de boards précédemment\n",
    "    num_board_end=random.randint(5,len(list_moves))\n",
    "\n",
    "    boards_interest=boards[:,:,num_board_end-nb_boards_of_interest:num_board_end] #à modifier, faut juste qu'on puiss récupérer les 4 boards précédents\n",
    "    #print(boards_interest.shape)\n",
    "    white_boards=np.zeros([9,9,nb_boards_of_interest])\n",
    "    black_boards=np.zeros([9,9,nb_boards_of_interest])\n",
    "    j=0\n",
    "    for j in range(boards_interest.shape[2]):\n",
    "        random_board=boards_interest[:,:,j]\n",
    "        black_board=np.zeros([9,9])\n",
    "\n",
    "        black_board=np.where(random_board==1,1,black_board)\n",
    "        black_boards[:,:,j]=black_board\n",
    "\n",
    "\n",
    "        white_board=np.zeros([9,9])\n",
    "\n",
    "        white_board=np.where(random_board==2,2,white_board)\n",
    "        white_boards[:,:,j]=white_board\n",
    "\n",
    "        j+=1\n",
    "    \n",
    "    #c'est le joueur noir qui joue en premier\n",
    "    #donc noir joue le coup 0\n",
    "    #donc noir a joué les coups pairs\n",
    "    #donc blanc joue le prochain coup\n",
    "    if(num_board_end%2==0):\n",
    "        player='white'\n",
    "    else:\n",
    "        player='black'\n",
    "        \n",
    "    if(player=='white'): #si c'est pair, c'est aux blancs de jouer\n",
    "        next_player=np.zeros([9,9])\n",
    "        value=(first_game.get('white_wins'))/100\n",
    "    else:\n",
    "        next_player=np.ones([9,9])\n",
    "        value=first_game.get('black_wins')/100\n",
    "    #on récupère ensuite l'entier qui correspond à la position dans la liste du coup joué\n",
    "    next_move=num_board_end + 1\n",
    "    #print(next_move)\n",
    "    #a=input()\n",
    "\n",
    "\n",
    "    #déjà on prend un board\n",
    "    input_data=np.zeros([9,9,9])\n",
    "    #on prend \n",
    "    input_data[:,:,0:nb_boards_of_interest]=white_boards\n",
    "    input_data[:,:,nb_boards_of_interest:nb_boards_of_interest*2]=black_boards\n",
    "    input_data[:,:,nb_boards_of_interest*2]=next_player\n",
    "    #faut aussi return la proba de gagner\n",
    "    return (input_data, value,next_move)\n",
    "\n",
    "\n",
    "dataset=get_raw_data_go()\n",
    "#sample, value=generate_single_data(dataset)\n",
    "#print(sample.shape)\n",
    "#print(sample[:,2,:])\n",
    "#ça a l'air bon, on a la bonne shape\n",
    "#print(value)\n",
    "\n",
    "#on crée un tableau \n",
    "nb_samples=100000\n",
    "tab_features_multiple=np.zeros([nb_samples,9,9,9])\n",
    "tab_labels_value=np.zeros(nb_samples)\n",
    "tab_labels_next_move=np.zeros(nb_samples)\n",
    "\n",
    "for i in range(nb_samples):\n",
    "    sample=np.zeros([9,9,9])\n",
    "    value=0\n",
    "    sample, value, next_move=generate_single_data(dataset)\n",
    "    \n",
    "    tab_features_multiple[i,:,:,:]=sample\n",
    "    tab_labels_value[i]=value\n",
    "    tab_labels_next_move[i] =next_move\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#il y a des erreurs même dans 50 samples,  key error: 24\n",
    "\n",
    "#le problème c'est qu'il push plusieurs fois le même move\n",
    "\n",
    "#on voit sur l'exemple suivant qu'effectivement, on push plusieurs fois le même move\n",
    "#je vois pas trop comment c'est possible\n",
    "#on save features et labels\n",
    "np.save('Features_multiple.npy',tab_features_multiple)\n",
    "np.save('Labels_value.npy',tab_labels_value)\n",
    "np.save('Labels_next_move.npy',tab_labels_next_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTmIkhCxDBqG",
    "outputId": "f8c034eb-dddf-4ed2-9272-7a7a9f9c6ffb"
   },
   "outputs": [],
   "source": [
    "features=np.load('Features_multiple.npy')\n",
    "labels_value=np.load('Labels_value.npy')\n",
    "labels_next_move=np.load('Labels_next_move.npy')\n",
    "print(features.shape)\n",
    "print(labels_next_move.shape)\n",
    "print(labels_value.shape)\n",
    "\n",
    "final_label_moves=np.zeros([labels_next_move.shape[0], 83])\n",
    "for i in range(final_label_moves.shape[0]):\n",
    "  j=labels_next_move[i]\n",
    "  j=int(j)\n",
    "  print(i)\n",
    "  print(j)\n",
    "  final_label_moves[i,j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RsQyTmjjoDlD"
   },
   "outputs": [],
   "source": [
    "#residual_tower\n",
    "\n",
    "visible=Input(shape=(9,9,9))\n",
    "conv1=Conv2D(256,(3,3), strides=(1, 1), input_shape=(9,9,9), padding='same') (visible)\n",
    "norm1= BatchNormalization() (conv1)\n",
    "output= Activation(relu) (norm1)\n",
    "\n",
    "residual_tower=Model(inputs=visible, outputs=output)\n",
    "#print(residual_tower.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1oQAomDoqLU",
    "outputId": "34d010bc-63ce-4afd-eb13-8ee76933b93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 9, 9, 256)\n"
     ]
    }
   ],
   "source": [
    "#residual block\n",
    "\n",
    "visible=Input(shape=residual_tower.output_shape[1:])\n",
    "conv1=Conv2D(256,(3,3), strides=(1, 1), input_shape=residual_tower.output_shape[1:], padding='same') (visible)\n",
    "norm1= BatchNormalization() (conv1)\n",
    "act1= Activation(relu) (norm1)\n",
    "conv2=Conv2D(256,(3,3), strides=(1, 1), padding='same') (act1)\n",
    "norm2= BatchNormalization() (conv2)\n",
    "#residual layer\n",
    "act2=Activation(relu, trainable=False) (norm2)\n",
    "conv3=Conv2D(256,(3,3), strides=(1, 1), padding='same') (act2)\n",
    "act3=Activation(relu) (conv3)\n",
    "conv4=Conv2D(256,(3,3), strides=(1, 1), padding='same') (act3)\n",
    "residual=Add() ([conv4, act2])\n",
    "#act5=Activation(relu) (residual)\n",
    "#res1=Residual(256,(9,9)) (norm2)\n",
    "output=Activation(relu) (residual)\n",
    "residual_block=Model(inputs=visible, outputs=output)\n",
    "\n",
    "print(residual_block.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgDeBofZprCG",
    "outputId": "7f8b9e4c-7082-408f-b540-f44e143f1195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "#value head\n",
    "visible=Input(shape=residual_block.output_shape[1:])\n",
    "conv1= Conv2D(1,(1,1), strides=(1, 1), input_shape=residual_block.output_shape[1:], padding='same') (visible)\n",
    "norm1= BatchNormalization() (conv1)\n",
    "act1= Activation(relu) (norm1)\n",
    "flat1= Flatten() (act1)\n",
    "dense1= Dense(256, activation='relu') (flat1)\n",
    "output= Dense(1, activation='tanh') (dense1)\n",
    "\n",
    "value_head=Model(inputs=visible, outputs=output)\n",
    "print(value_head.output_shape)\n",
    "\n",
    "visible=Input(shape=(9,9,9))\n",
    "output_residual_tower=residual_tower(visible)\n",
    "for i in range(19):\n",
    "  if(i==0): #on prend la sortie de residual tower\n",
    "    output_residual_block=residual_block(output_residual_tower)\n",
    "  else:\n",
    "    output_residual_block=residual_block(output_residual_block)\n",
    "output_value=value_head(output_residual_block)\n",
    "value_model=Model(inputs=visible, outputs=output_value)\n",
    "print(value_model.output_shape)\n",
    "\n",
    "\n",
    "value_model.compile(\n",
    "#loss=my_loss_fn,\n",
    "#loss=['mean_squared_error', 'categorical_crossentropy'],\n",
    "loss='mean_squared_error',\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#value_model.fit(features,  labels_value, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NdDvQeJw5Vq",
    "outputId": "7cc60b85-373b-44bb-aeae-861127c59401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 83)\n"
     ]
    }
   ],
   "source": [
    "#policy_head\n",
    "\n",
    "visible=Input(shape=residual_block.output_shape[1:])\n",
    "conv1=Conv2D(2,(1,1), strides=(1, 1), input_shape=residual_block.output_shape[1:], padding='same') (visible)\n",
    "norm1= BatchNormalization() (conv1)\n",
    "act1= Activation(relu) (norm1)\n",
    "flat1= Flatten() (act1)\n",
    "output=Dense(83, activation='softmax') (flat1)\n",
    "\n",
    "policy_head=Model(inputs=visible, outputs=output)\n",
    "\n",
    "visible=Input(shape=(9,9,9))\n",
    "output_residual_tower=residual_tower(visible)\n",
    "for i in range(19):\n",
    "  if(i==0): #on prend la sortie de residual tower\n",
    "    output_residual_block=residual_block(output_residual_tower)\n",
    "  else:\n",
    "    output_residual_block=residual_block(output_residual_block)\n",
    "output_value=policy_head(output_residual_block)\n",
    "policy_model=Model(inputs=visible, outputs=output_value)\n",
    "print(policy_model.output_shape)\n",
    "\n",
    "policy_model.compile(\n",
    "#loss=my_loss_fn,\n",
    "#loss=['mean_squared_error', 'categorical_crossentropy'],\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "metrics=['accuracy']\n",
    "#metrics=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    ")\n",
    "\n",
    "#je suis censé prédire une distribution de probabilités avec un vecteur\n",
    "#de 82 composantes. je dois donc avoir softmax\n",
    "\n",
    "#policy_model.fit(features,  final_label_moves, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxWKakptxkOT",
    "outputId": "99b51596-4864-4e4e-d790-1d0dfe6543d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 1), (None, 83)]\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 3.0142 - model_9_loss: 0.1417 - model_14_loss: 2.8725 - model_9_accuracy: 0.1776 - model_14_accuracy: 0.1887\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 987s 629ms/step - loss: 3.0142 - model_9_loss: 0.1417 - model_14_loss: 2.8725 - model_9_accuracy: 0.1776 - model_14_accuracy: 0.1887\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.5251 - model_9_loss: 0.1209 - model_14_loss: 1.4042 - model_9_accuracy: 0.2189 - model_14_accuracy: 0.5018\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 983s 629ms/step - loss: 1.5251 - model_9_loss: 0.1209 - model_14_loss: 1.4042 - model_9_accuracy: 0.2189 - model_14_accuracy: 0.5018\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.2150 - model_9_loss: 0.1162 - model_14_loss: 1.0988 - model_9_accuracy: 0.2359 - model_14_accuracy: 0.5738\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 984s 629ms/step - loss: 1.2150 - model_9_loss: 0.1162 - model_14_loss: 1.0988 - model_9_accuracy: 0.2359 - model_14_accuracy: 0.5738\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.1195 - model_9_loss: 0.1161 - model_14_loss: 1.0034 - model_9_accuracy: 0.2358 - model_14_accuracy: 0.6119\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 984s 629ms/step - loss: 1.1195 - model_9_loss: 0.1161 - model_14_loss: 1.0034 - model_9_accuracy: 0.2358 - model_14_accuracy: 0.6119\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9801 - model_9_loss: 0.1156 - model_14_loss: 0.8645 - model_9_accuracy: 0.2364 - model_14_accuracy: 0.6630\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 984s 629ms/step - loss: 0.9801 - model_9_loss: 0.1156 - model_14_loss: 0.8645 - model_9_accuracy: 0.2364 - model_14_accuracy: 0.6630\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8263 - model_9_loss: 0.1151 - model_14_loss: 0.7112 - model_9_accuracy: 0.2370 - model_14_accuracy: 0.7236\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 982s 628ms/step - loss: 0.8263 - model_9_loss: 0.1151 - model_14_loss: 0.7112 - model_9_accuracy: 0.2370 - model_14_accuracy: 0.7236\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7208 - model_9_loss: 0.1151 - model_14_loss: 0.6057 - model_9_accuracy: 0.2369 - model_14_accuracy: 0.7681\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 982s 628ms/step - loss: 0.7208 - model_9_loss: 0.1151 - model_14_loss: 0.6057 - model_9_accuracy: 0.2369 - model_14_accuracy: 0.7681\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6242 - model_9_loss: 0.1148 - model_14_loss: 0.5094 - model_9_accuracy: 0.2372 - model_14_accuracy: 0.8042\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 982s 628ms/step - loss: 0.6242 - model_9_loss: 0.1148 - model_14_loss: 0.5094 - model_9_accuracy: 0.2372 - model_14_accuracy: 0.8042\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5261 - model_9_loss: 0.1144 - model_14_loss: 0.4117 - model_9_accuracy: 0.2375 - model_14_accuracy: 0.8418\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 981s 628ms/step - loss: 0.5261 - model_9_loss: 0.1144 - model_14_loss: 0.4117 - model_9_accuracy: 0.2375 - model_14_accuracy: 0.8418\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4863 - model_9_loss: 0.1144 - model_14_loss: 0.3719 - model_9_accuracy: 0.2375 - model_14_accuracy: 0.8555\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "1563/1563 [==============================] - 984s 630ms/step - loss: 0.4863 - model_9_loss: 0.1144 - model_14_loss: 0.3719 - model_9_accuracy: 0.2375 - model_14_accuracy: 0.8555\n",
      "Epoch 11/50\n",
      " 307/1563 [====>.........................] - ETA: 13:08 - loss: 0.4425 - model_9_loss: 0.1136 - model_14_loss: 0.3289 - model_9_accuracy: 0.2345 - model_14_accuracy: 0.8725"
     ]
    }
   ],
   "source": [
    "#global model with 2 outputs\n",
    "visible=Input(shape=(9,9,9))\n",
    "output_residual_tower=residual_tower(visible)\n",
    "for i in range(19):\n",
    "  if(i==0): #on prend la sortie de residual tower\n",
    "    output_residual_block=residual_block(output_residual_tower)\n",
    "  else:\n",
    "    output_residual_block=residual_block(output_residual_block)\n",
    "output_value=value_head(output_residual_block)\n",
    "output_policy=policy_head(output_residual_block)\n",
    "global_model=Model(inputs=visible, outputs=[output_value, output_policy])\n",
    "print(global_model.output_shape)\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "global_model.compile(\n",
    "#loss=my_loss_fn,\n",
    "loss=['mean_squared_error', 'categorical_crossentropy'],\n",
    "#loss='sparse_categorical_crossentropy',\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "global_model.fit(features,  [labels_value, final_label_moves], batch_size=64, epochs=50, callbacks=[cp_callback])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NNV5.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
